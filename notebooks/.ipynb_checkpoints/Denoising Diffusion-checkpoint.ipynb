{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3371fb0b-26dd-4068-948e-7b95ee1e5e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/cruzcastrol/dthiyagarajan/.conda/envs/eoi/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange #pip install einops\n",
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader \n",
    "from timm.utils import ModelEmaV3 #pip install timm \n",
    "from tqdm import tqdm #pip install tqdm\n",
    "import matplotlib.pyplot as plt #pip install matplotlib\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d2f168-8a4c-42ad-ac68-ccfe543d7c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "root_directory = os.path.dirname(os.getcwd())\n",
    "#print(os.path.join(root_directory, 'src'))\n",
    "sys.path.append(os.path.join(root_directory, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf0e8b8-61ea-40b9-aa87-227908d658b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from text_encoders import clip_model, bert_model\n",
    "from dataloaders import caption_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10500af3-156d-44eb-b6fa-336846a21d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SinusoidalEmbeddings(nn.Module):\n",
    "    def __init__(self, time_steps:int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        position = torch.arange(time_steps).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))\n",
    "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
    "        embeddings[:, 0::2] = torch.sin(position * div)\n",
    "        embeddings[:, 1::2] = torch.cos(position * div)\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        embeds = self.embeddings.to(t.device)[t]  \n",
    "        return embeds[:, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7818de6-c0c4-4bcc-8ea5-a1e48ecfbaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n",
    "\n",
    "    def forward(self, x, embeddings):\n",
    "        x = x + embeddings[:, :x.shape[1], :, :]\n",
    "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
    "        r = self.dropout(r)\n",
    "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
    "        return r + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbdca158-d807-4f69-88c7-cfc0e5a1304e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, C: int, num_heads:int , dropout_prob: float):\n",
    "        super().__init__()\n",
    "        self.proj1 = nn.Linear(C, C*3)\n",
    "        self.proj2 = nn.Linear(C, C)\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[2:]\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        x = self.proj1(x)\n",
    "        x = rearrange(x, 'b L (C H K) -> K b H L C', K=3, H=self.num_heads)\n",
    "        q,k,v = x[0], x[1], x[2]\n",
    "        x = F.scaled_dot_product_attention(q,k,v, is_causal=False, dropout_p=self.dropout_prob)\n",
    "        x = rearrange(x, 'b H (h w) C -> b h w (C H)', h=h, w=w)\n",
    "        x = self.proj2(x)\n",
    "        return rearrange(x, 'b h w C -> b C h w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6f2508-401d-4ee9-a789-4e1ac53ac778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "            upscale: bool, \n",
    "            attention: bool, \n",
    "            num_groups: int, \n",
    "            dropout_prob: float,\n",
    "            num_heads: int,\n",
    "            C: int):\n",
    "        super().__init__()\n",
    "        self.ResBlock1 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n",
    "        self.ResBlock2 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n",
    "        if upscale:\n",
    "            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n",
    "        if attention:\n",
    "            self.attention_layer = Attention(C, num_heads=num_heads, dropout_prob=dropout_prob)\n",
    "\n",
    "    def forward(self, x, embeddings):\n",
    "        x = self.ResBlock1(x, embeddings)\n",
    "        if hasattr(self, 'attention_layer'):\n",
    "            x = self.attention_layer(x)\n",
    "        x = self.ResBlock2(x, embeddings)\n",
    "        return self.conv(x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e372a3-a2ef-4751-a607-1aec7b3969d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self,\n",
    "                 Channels: List = [64, 128, 256, 512, 512, 384],\n",
    "                 Attentions: List = [False, True, False, False, False, True],\n",
    "                 Upscales: List = [False, False, False, True, True, True],\n",
    "                 num_groups: int = 32,\n",
    "                 dropout_prob: float = 0.1,\n",
    "                 num_heads: int = 8,\n",
    "                 input_channels: int = 1,\n",
    "                 output_channels: int = 1,\n",
    "                 time_steps: int = 1000,\n",
    "                 text_embed_dim: int = 512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = len(Channels)\n",
    "        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n",
    "        self.late_conv = nn.Conv2d((Channels[-1]//2)+Channels[0], (Channels[-1]//2), kernel_size=3, padding=1)\n",
    "        self.output_conv = nn.Conv2d((Channels[-1]//2), output_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n",
    "\n",
    "        # Project text embeddings to same dim\n",
    "        self.text_proj = nn.Linear(text_embed_dim, max(Channels))\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            layer = UnetLayer(\n",
    "                upscale=Upscales[i],\n",
    "                attention=Attentions[i],\n",
    "                num_groups=num_groups,\n",
    "                dropout_prob=dropout_prob,\n",
    "                C=Channels[i],\n",
    "                num_heads=num_heads\n",
    "            )\n",
    "            setattr(self, f'Layer{i+1}', layer)\n",
    "\n",
    "    def forward(self, x, t, text_emb):\n",
    "        x = self.shallow_conv(x)\n",
    "        residuals = []\n",
    "\n",
    "        # ðŸ”¹ Combine time and text embeddings\n",
    "        text_emb = self.text_proj(text_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        time_emb = self.embeddings(x, t)\n",
    "        combined_emb = time_emb + text_emb  # fused conditioning\n",
    "\n",
    "        for i in range(self.num_layers // 2):\n",
    "            layer = getattr(self, f'Layer{i+1}')\n",
    "            x, r = layer(x, combined_emb)\n",
    "            residuals.append(r)\n",
    "\n",
    "        for i in range(self.num_layers // 2, self.num_layers):\n",
    "            layer = getattr(self, f'Layer{i+1}')\n",
    "            x = torch.concat((layer(x, combined_emb)[0], residuals[self.num_layers - i - 1]), dim=1)\n",
    "\n",
    "        return self.output_conv(self.relu(self.late_conv(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa7a68d-873e-4e63-bd48-bb1a5e250e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DDPM_Scheduler(nn.Module):\n",
    "    def __init__(self, num_time_steps: int=1000):\n",
    "        super().__init__()\n",
    "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False)\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        return self.beta.to(device)[t], self.alpha.to(device)[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074f0455-9b0c-43ce-bc4a-d67982de08f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b32877-9cff-47d6-8b8e-d120898bec45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/blue/eee6778/dthiyagarajan/Echoes-of-Imagination'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_directory = os.path.dirname(os.getcwd())\n",
    "root_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913d31fe-ff88-4801-9cc8-6e8861b50546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = caption_dataset()\n",
    "train_dataloader = dataloader.get_dataloader(partition = \"train\", batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "704cd171-9b6f-4a48-954a-0f2caaf2cc09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 64, 64])\n",
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "imgs, text_emb = next(iter(train_dataloader))\n",
    "print(imgs.shape)       # [B, 3, H, W]\n",
    "print(text_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa383c17-7661-4b7b-898f-e2f180ed64b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
    "model = UNET(input_channels=3, output_channels=3, text_embed_dim=train_dataloader.dataset.embed_dim).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdba39-d9f9-4f16-827d-7f9cbeb3c7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29903/29903 [2:11:13<00:00,  3.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27796/29903 [2:01:14<09:11,  3.82it/s]  "
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for imgs, text_emb in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        imgs, text_emb = imgs.cuda(), text_emb.cuda()\n",
    "        b = imgs.size(0)\n",
    "\n",
    "        # sample timesteps\n",
    "        t = torch.randint(0, 1000, (b,), device=imgs.device)\n",
    "        e = torch.randn_like(imgs)\n",
    "\n",
    "        beta_t, alpha_t = scheduler(t)\n",
    "        a = alpha_t.view(b, 1, 1, 1)\n",
    "        noisy_imgs = (torch.sqrt(a) * imgs) + (torch.sqrt(1 - a) * e)\n",
    "\n",
    "        pred_noise = model(noisy_imgs, t, text_emb)\n",
    "        loss = criterion(pred_noise, e)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d24928-f8a5-4c21-b00b-fe3fc59948a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8bfc2-b766-4d14-821b-ae9fb638b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eoi_project",
   "language": "python",
   "name": "eoi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
